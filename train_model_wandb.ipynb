{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec09825-b8c8-4e3b-b094-686b93c964e2",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "2ec09825-b8c8-4e3b-b094-686b93c964e2",
     "kernelId": "51c482b6-bbad-41c4-87b8-5fee8953926e",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!pip install wandb -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07561b5f-89b6-46b1-9ea8-0a1c6f10fc19",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "07561b5f-89b6-46b1-9ea8-0a1c6f10fc19",
     "kernelId": "51c482b6-bbad-41c4-87b8-5fee8953926e",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf80c8a-4997-44b5-9129-3ae74d37d844",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "baf80c8a-4997-44b5-9129-3ae74d37d844",
     "kernelId": "51c482b6-bbad-41c4-87b8-5fee8953926e",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"./train_model_wandb.ipynb\"\n",
    "\n",
    "# Log in to your W&B account\n",
    "wandb.login(key='<your-W&B-api-key>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be34c6b2-0a7a-4f40-8398-b61376d48277",
   "metadata": {
    "collapsed": true,
    "gradient": {
     "editing": false,
     "id": "be34c6b2-0a7a-4f40-8398-b61376d48277",
     "kernelId": "51c482b6-bbad-41c4-87b8-5fee8953926e",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import sys, getopt\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "from resnet import resnet18, resnet34\n",
    "from load_data import trainloader, testloader, valloader\n",
    "from config.config import model_config\n",
    "\n",
    "models = ['ResNet18', 'ResNet34']\n",
    "\n",
    "for model in models:\n",
    "    with wandb.init(project=\"resnet-test\", config=model_config, name=model):\n",
    "\n",
    "        print(model_config['epochs'])\n",
    "        print(model_config['batch_size'])\n",
    "        print(model_config['lr'])\n",
    "        print(model)\n",
    "\n",
    "        if model == 'ResNet18':\n",
    "            model = resnet18(3, 10)\n",
    "        else:\n",
    "            model = resnet34(3, 10)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        # optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "        optimizer = optim.SGD(model.parameters(), lr=model_config['lr'], momentum=0.9)\n",
    "\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model.to(device)\n",
    "\n",
    "        step = 0\n",
    "        epoch_durations = []\n",
    "        for epoch in range(model_config['epochs']):\n",
    "            \n",
    "            start_epoch_time = time.time()\n",
    "            # print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "            print('epoch:', epoch+1)\n",
    "            mini_batch_check=50\n",
    "            running_loss = 0.0\n",
    "            model.train()\n",
    "\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                # print(i)\n",
    "\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # print statistics\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                if i % mini_batch_check == mini_batch_check-1:    # print every 50 mini-batches\n",
    "                    step +=1\n",
    "                    print('inter-epoch:', epoch + ((i+1)/len(trainloader)))\n",
    "                    wandb.log({\"train_loss\": running_loss/mini_batch_check, \"epoch\": epoch + ((i+1)/len(trainloader))}, step=step)\n",
    "\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                        (epoch + 1, i + 1, running_loss / mini_batch_check))\n",
    "                    \n",
    "                    running_loss = 0.0\n",
    "            \n",
    "            val_loss, accuracy = validate_model(model, valloader, criterion)\n",
    "                \n",
    "            # Log validation metrics\n",
    "            wandb.log({\"val_loss\": val_loss, \"val_accuracy\": accuracy}, step=step)\n",
    "            print(f\"Valid Loss: {val_loss:3f}, accuracy: {accuracy:.2f}\")\n",
    "            epoch_duration = time.time() - start_epoch_time\n",
    "            wandb.log({\"epoch_runtime (seconds)\": epoch_duration}, step=step)\n",
    "\n",
    "            epoch_durations.append(epoch_duration)\n",
    "\n",
    "        avg_epoch_runtime = sum(epoch_durations) / len(epoch_durations)\n",
    "        wandb.log({\"avg epoch runtime (seconds)\": avg_epoch_runtime})\n",
    "        # wandb.finish()\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a23d1d-229a-458e-a422-87d82c9efc04",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "d3a23d1d-229a-458e-a422-87d82c9efc04",
     "kernelId": "51c482b6-bbad-41c4-87b8-5fee8953926e",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def validate_model(model, valid_dl, loss_func, log_images=False, batch_idx=0):\n",
    "    \"Compute performance of the model on the validation dataset and log a wandb.Table\"\n",
    "    model.eval()\n",
    "    val_loss = 0.\n",
    "    with torch.inference_mode():\n",
    "        correct = 0\n",
    "        for i, (images, labels) in enumerate(valid_dl, 0):\n",
    "        # for i, (images, labels) in enumerate(valid_dl), leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass âž¡\n",
    "            outputs = model(images)\n",
    "            val_loss += loss_func(outputs, labels)*labels.size(0)\n",
    "\n",
    "            # Compute accuracy and accumulate\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Log one batch of images to the dashboard, always same batch_idx.\n",
    "            # if i==batch_idx and log_images:\n",
    "                # log_image_table(images, predicted, labels, outputs.softmax(dim=1))\n",
    "    return val_loss / len(valid_dl.dataset), correct / len(valid_dl.dataset)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
